{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/juanfranbrv/curso-langchain/blob/main/RAG_1.ipynb",
      "authorship_tag": "ABX9TyMFZxs9dlVv9UfF8RX0MYqF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfranbrv/curso-langchain/blob/main/RAG_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "\n",
        "# Importar la librería `userdata` de Google Colab.\n",
        "# Esta librería se utiliza para acceder a datos de usuario almacenados de forma segura en el entorno de Colab.\n",
        "from google.colab import userdata\n",
        "\n",
        "# Obtener las claves API de diferentes servicios desde el almacenamiento seguro de Colab.\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN=userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "MISTRAL_API_KEY=userdata.get('MISTRAL_API_KEY')\n",
        "TOGETHER_API_KEY=userdata.get('TOGETHER_API_KEY')\n",
        "ANTHROPIC_API_KEY=userdata.get('ANTHROPIC_API_KEY')\n",
        "DEEPSEEK_API_KEY=userdata.get('DEEPSEEK_API_KEY')\n",
        "\n",
        "\n",
        "# Instalar las librerías necesarias usando pip.\n",
        "# El flag `-qU` instala en modo silencioso (`-q`) y actualiza las librerías si ya están instaladas (`-U`).\n",
        "%pip install langchain -qU  # Instalar la librería principal de LangChain.\n",
        "\n",
        "\n",
        "# Instalar las integraciones de LangChain con diferentes proveedores de LLMs.\n",
        "%pip install langchain-openai -qU\n",
        "%pip install langchain-groq -qU\n",
        "%pip install langchain-google-genai -qU\n",
        "%pip install langchain-huggingface -qU\n",
        "%pip install langchain_mistralai -qU\n",
        "%pip install langchain-together -qU\n",
        "%pip install langchain-anthropic -qU\n",
        "%pip install langchain-deepseek -qU\n",
        "\n",
        "\n",
        "%pip install langchain_community -qU\n",
        "%pip install langchainhub -qU\n",
        "%pip install langchain-text-splitters -qU\n",
        "\n",
        "%pip install chromadb langchain-chroma -qU\n",
        "%pip install langchain-chromadb -qU\n",
        "\n",
        "\n",
        "# Para web scraping con LangChaig\n",
        "%pip install requests -qU\n",
        "%pip install beautifulsoup4 -qU\n",
        "\n",
        "\n",
        "\n",
        "# Importar las clases necesarias de LangChain para crear plantillas de prompt.\n",
        "# `ChatPromptTemplate` es la clase base para plantillas de chat.\n",
        "# `SystemMessagePromptTemplate` se usa para mensajes del sistema (instrucciones iniciales).\n",
        "# `HumanMessagePromptTemplate` se usa para mensajes del usuario.\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# Importar las clases para interactuar con los diferentes LLMs a través de LangChain.\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain_together import ChatTogether\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "# from langchain_deepseek import ChatDeepSeek\n",
        "\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "import bs4\n",
        "\n",
        "\n",
        "# Importamos la libreria para formatear mejor la salida\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "Nqml2kPRzN36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bs4.SoupStrainer: Es una clase de BeautifulSoup que permite filtrar el contenido HTML durante el análisis (parsing). En lugar de analizar todo el documento HTML, solo se analizan las partes que coinciden con el filtro especificado.\n",
        "\n",
        "class_=\"content_area\": Este filtro indica que solo se deben analizar los elementos HTML que tengan la clase CSS content_area. El uso de class_ (con un guion bajo al final) es necesario porque class es una palabra reservada en Python."
      ],
      "metadata": {
        "id": "cCwcA-mUNVCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define un USER_AGENT válido\n",
        "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "\n",
        "\n",
        "bs4_strainer = bs4.SoupStrainer(id=\"bodyContent\")\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://es.wikipedia.org/wiki/Edificio_Chrysler\",),\n",
        "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "id": "myX1S5Fq3Tno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CzDi4JF0YCWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1200, chunk_overlap=100, add_start_index=True\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "all_splits"
      ],
      "metadata": {
        "id": "qyt5ntgPYDZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2tNrUvSUZYId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
        "\n",
        "embeddings"
      ],
      "metadata": {
        "id": "XnQFKH0GZYoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Od0N7vOmZfXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Crear vector store\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=all_splits,\n",
        "    embedding=embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "Bc-wNJSGZf28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "85B8PRMHZ1cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r-RsML7lZ17U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FFDm4rNKaJKz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZMwzMg3fB0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pregunta = \"Cuantas ventanas tiene el edificio Chrysler ?\"\n",
        "retrieved_docs = retriever.invoke(pregunta)\n",
        "\n",
        "for doc in retrieved_docs:\n",
        "    display(Markdown(doc.page_content))\n",
        "    print(\"---\\n\")\n"
      ],
      "metadata": {
        "id": "JjkDVkBeaJsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zPXnH2DpdCSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contexto = ' '.join([doc.page_content for doc in retrieved_docs])\n",
        "\n",
        "contexto"
      ],
      "metadata": {
        "id": "7D4r72OadC6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d-yV1yyddfnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de lenguaje\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\",api_key=OPENAI_API_KEY, temperature=0.7)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7qTsuhOZdgE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respuesta = llm.invoke(f\"\"\"Usando el contexto proporcionado, responde a la pregunta. Si no lo sabes, responde simplemente 'No lo se'\n",
        "           Pregunta: {pregunta}.\n",
        "           Contexto: {contexto}\n",
        "\"\"\")\n",
        "\n",
        "display(Markdown(respuesta.content))"
      ],
      "metadata": {
        "id": "nadBSP1udjZe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}