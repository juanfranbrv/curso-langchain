{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCpUhXLgPyH2axc5M1uuUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfranbrv/curso-langchain/blob/main/agents_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. Preparando el cuaderno**\n",
        "---\n",
        "bla, bla, bla"
      ],
      "metadata": {
        "id": "HwyvZdZVeOOd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsW4sWtvd7zT"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "\n",
        "# Importar la librería `userdata` de Google Colab.\n",
        "# Esta librería se utiliza para acceder a datos de usuario almacenados de forma segura en el entorno de Colab.\n",
        "from google.colab import userdata\n",
        "\n",
        "# Obtener las claves API de diferentes servicios desde el almacenamiento seguro de Colab.\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN=userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "# Instalar las librerías necesarias usando pip.\n",
        "# El flag `-qU` instala en modo silencioso (`-q`) y actualiza las librerías si ya están instaladas (`-U`).\n",
        "%pip install langchain -qU  # Instalar la librería principal de LangChain.\n",
        "%pip install langgraph -qU  # Instalar la librería de grafos de LangChain.\n",
        "\n",
        "# Instalar las integraciones de LangChain con diferentes proveedores de LLMs.\n",
        "%pip install langchain-openai -qU\n",
        "%pip install langchain-groq -qU\n",
        "%pip install langchain-google-genai -qU\n",
        "%pip install langchain-huggingface -qU\n",
        "\n",
        "# Importar las clases necesarias de LangChain para crear plantillas de prompt.\n",
        "# `ChatPromptTemplate` es la clase base para plantillas de chat.\n",
        "# `SystemMessagePromptTemplate` se usa para mensajes del sistema (instrucciones iniciales).\n",
        "# `HumanMessagePromptTemplate` se usa para mensajes del usuario.\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "\n",
        "# # Importamos las clases necesarias para trabajar con cadenas\n",
        "# from langchain.chains import LLMChain\n",
        "\n",
        "# Importar las clases para interactuar con los diferentes LLMs a través de LangChain.\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "# Importamos la libreria para formatear mejor la salida\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, TypedDict\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "# 1. Definir el estado del grafo\n",
        "class TranslationState(TypedDict):\n",
        "    original_text: str\n",
        "    source_language: str\n",
        "    target_language: str\n",
        "    translator_output: str\n",
        "    reviewer_suggestions: List[str]\n",
        "    editor_output: str\n",
        "    translation_iterations: int\n",
        "\n",
        "# 2. Definir las plantillas\n",
        "translator_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"Eres un lingüista experto, especializado en traducción del lenguaje \"\n",
        "        \"{source_language} al {target_language}. Utiliza técnicas avanzadas para \"\n",
        "        \"proporcionar traducciones fluidas y precisas.\"\n",
        "    )),\n",
        "    (\"human\", (\n",
        "        \"Traduce el siguiente texto del {source_language} al {target_language}:\\n\"\n",
        "        \"{original_text}\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "reviewer_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"Eres un lingüista experto, especializado en traducción del lenguaje \"\n",
        "        \"{source_language} al {target_language}. Se te proporcionará un texto original \"\n",
        "        \"y una traducción. Tu objetivo es mejorar la traducción y dar sugerencias. \"\n",
        "        \"Si la traducción está perfectamente bien y no se requieren cambios, \"\n",
        "        \"devuelve exactamente la palabra 'NO_SUGERENCIAS'.\"\n",
        "    )),\n",
        "    (\"human\", (\n",
        "        \"Texto original ({source_language}):\\n{original_text}\\n\\n\"\n",
        "        \"Traducción del traductor:\\n{translator_output}\\n\\n\"\n",
        "        \"Proporciona sugerencias y críticas constructivas:\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "editor_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"Eres un lingüista experto, especializado en traducción del {source_language} \"\n",
        "        \"al {target_language}. Tu tarea es leer y editar la traducción final, \"\n",
        "        \"aplicando las sugerencias relevantes.\"\n",
        "    )),\n",
        "    (\"human\", (\n",
        "        \"Traducción del traductor:\\n{translator_output}\\n\\n\"\n",
        "        \"Sugerencias del revisor:\\n{reviewer_suggestions}\\n\\n\"\n",
        "        \"Realiza la edición final de la traducción:\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 3. Configurar el modelo\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, temperature=0.7)\n",
        "\n",
        "# 4. Crear runnables\n",
        "translator_chain = translator_prompt | llm\n",
        "reviewer_chain = reviewer_prompt | llm\n",
        "editor_chain = editor_prompt | llm\n",
        "\n",
        "# 5. Definir funciones de nodo\n",
        "def translate(state: TranslationState) -> dict:\n",
        "    print(\"\\n--- TRADUCIENDO ---\")\n",
        "    result = translator_chain.invoke(state)\n",
        "    print(f\"Traducción inicial: {result.content}\")\n",
        "    return {\"translator_output\": result.content}\n",
        "\n",
        "def review(state: TranslationState) -> dict:\n",
        "    print(\"\\n--- REVISANDO ---\")\n",
        "    result = reviewer_chain.invoke(state)\n",
        "    content = result.content.strip()\n",
        "    if content == \"NO_SUGERENCIAS\":\n",
        "        suggestions = []\n",
        "    else:\n",
        "        suggestions = [line.strip() for line in content.split(\"\\n\") if line.strip()]\n",
        "    print(f\"Sugerencias del revisor: {suggestions}\")\n",
        "    return {\"reviewer_suggestions\": suggestions}\n",
        "\n",
        "def edit(state: TranslationState) -> dict:\n",
        "    print(\"\\n--- EDITANDO ---\")\n",
        "    result = editor_chain.invoke(state)\n",
        "    print(f\"Edición final: {result.content}\")\n",
        "    return {\"editor_output\": result.content}\n",
        "\n",
        "def decide_next_step(state: TranslationState) -> dict:\n",
        "    max_iterations = 3\n",
        "    suggestions = state.get(\"reviewer_suggestions\", [])\n",
        "    current_iter = state[\"translation_iterations\"]  # Leer el valor actual\n",
        "\n",
        "    # SOLO si hay sugerencias y no se ha llegado al tope:\n",
        "    if suggestions and current_iter < max_iterations:\n",
        "        current_iter += 1\n",
        "        print(f\"\\nEl revisor ha hecho sugerencias. Iteración n.º {current_iter}. Volvemos a traducir.\")\n",
        "        return {\n",
        "            \"translation_iterations\": current_iter,\n",
        "            \"decision\": \"translate\"\n",
        "        }\n",
        "    else:\n",
        "        print(\"\\nEl revisor no ha hecho sugerencias o se alcanzó el máximo de iteraciones. Pasando a 'edit'.\")\n",
        "        return {\n",
        "            \"translation_iterations\": current_iter,\n",
        "            \"decision\": \"edit\"\n",
        "        }\n",
        "\n",
        "# 6. Construir el grafo\n",
        "builder = StateGraph(TranslationState)\n",
        "\n",
        "builder.add_node(\"translate\", translate)\n",
        "builder.add_node(\"review\", review)\n",
        "builder.add_node(\"edit\", edit)\n",
        "builder.add_node(\"check_review\", decide_next_step)\n",
        "\n",
        "builder.set_entry_point(\"translate\")\n",
        "\n",
        "builder.add_edge(\"translate\", \"review\")\n",
        "builder.add_edge(\"review\", \"check_review\")\n",
        "\n",
        "builder.add_conditional_edges(\n",
        "    \"check_review\",\n",
        "    lambda out: out[\"decision\"],  # cómo leer la decisión\n",
        "    {\n",
        "        \"translate\": \"translate\",\n",
        "        \"edit\": \"edit\"\n",
        "    }\n",
        ")\n",
        "\n",
        "builder.add_edge(\"edit\", END)\n",
        "graph = builder.compile()\n",
        "\n",
        "# 8. Ejecutar\n",
        "inputs = {\n",
        "    \"original_text\": \"Los Angeles firefighters were making modest progress in taming the region’s two largest fires on Saturday as they raced to suppress them ahead of high winds that were expected to intensify later in the day. After a night of expanded evacuation orders and spreading flames that continued to plunge the area into what Lindsey Horvath, a Los Angeles County supervisor, called 'unimaginable terror and heartbreak,' crews had contained 11 percent of the 22,660-acre Palisades fire and 15 percent of the 14,000-acre Eaton fire, near Altadena and Pasadena, according to Cal Fire.\",\n",
        "    \"source_language\": \"inglés\",\n",
        "    \"target_language\": \"español\",\n",
        "    \"translation_iterations\": 0\n",
        "}\n",
        "result = graph.invoke(inputs)\n",
        "\n",
        "# 9. Resultado\n",
        "print(\"\\n--- RESULTADO FINAL ---\")\n",
        "print(f\"Texto original: {result['original_text']}\")\n",
        "print(f\"Idioma de origen: {result['source_language']}\")\n",
        "print(f\"Idioma de destino: {result['target_language']}\")\n",
        "print(f\"Traducción final: {result.get('editor_output')}\")\n"
      ],
      "metadata": {
        "id": "_J0WZPK7uDO_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}