{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNRzAUeb9tsu1d2Whl7PT8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfranbrv/curso-langchain/blob/main/RunnableLamda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. `RunnableLambda`**\n",
        "---\n",
        "`RunnableLambda` es un componente clave en LangChain Expression Language (LCEL) que permite\n",
        "integrar funciones de Python estándar directamente en tus cadenas y flujos de trabajo.\n",
        "En esencia, `RunnableLambda` toma una función de Python y la convierte en un objeto\n",
        "\"runnable\" que puede ser parte de una cadena de LangChain, recibiendo la entrada del\n",
        "paso anterior y pasando su salida al siguiente.\n",
        "\n",
        "**¿Por qué usar RunnableLambda?**\n",
        "\n",
        "* **Flexibilidad:** Integra lógica de Python arbitraria dentro de tus cadenas de LangChain.  \n",
        "\n",
        "* **Simplicidad:** Envuelve funciones existentes sin necesidad de crear clases complejas.\n",
        "* **Modularidad:** Permite descomponer tareas complejas en funciones más pequeñas y reutilizables.\n",
        "* **Integración:** Facilita la conexión de LangChain con herramientas y librerías de Python.\n",
        "\n",
        "Vamos a ver a continuación varios ejemplos de uso"
      ],
      "metadata": {
        "id": "qiB5bQcHn93p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparando el entorno del cuaderno**\n",
        "---\n",
        "Configuramos el entorno de trabajo para utilizar LangChain con distintos modelos de lenguaje (LLMs).\n",
        "\n",
        "- Obtenemos las claves API para acceder a los servicios de OpenAI, Groq, Google Hugging Face, Mistral, Together y Anthropic\n",
        "\n",
        "- Instalamos la librería LangChain y las integraciones necesarias para cada uno de estos proveedores.\n",
        "\n",
        "- Importamos las clases específicas de LangChain que permiten crear plantillas de prompts e interactuar con los diferentes modelos de lenguaje, dejándolo todo listo para empezar a desarrollar aplicaciones basadas en LLMs. (Este codigo se explico con detalle en el primer cuaderno)\n",
        "\n",
        "Comenta (#) las librerias y modelos que no desees usar.\n",
        "El uso de las API de OpenAI y Anthropic es de pago. El resto son gratuitas y para usarlas basta con registrase y generar una API Key.  \n",
        "\n",
        "En el primer cuaderno encontraras los enlaces a estos servicios y este codigo explicado"
      ],
      "metadata": {
        "id": "sTF0Mzj_pjuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "\n",
        "# Importar la librería `userdata` de Google Colab.\n",
        "# Esta librería se utiliza para acceder a datos de usuario almacenados de forma segura en el entorno de Colab.\n",
        "from google.colab import userdata\n",
        "\n",
        "# Obtener las claves API de diferentes servicios desde el almacenamiento seguro de Colab.\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN=userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "MISTRAL_API_KEY=userdata.get('MISTRAL_API_KEY')\n",
        "TOGETHER_API_KEY=userdata.get('TOGETHER_API_KEY')\n",
        "\n",
        "\n",
        "# Instalar las librerías necesarias usando pip.\n",
        "# El flag `-qU` instala en modo silencioso (`-q`) y actualiza las librerías si ya están instaladas (`-U`).\n",
        "%pip install langchain -qU  # Instalar la librería principal de LangChain.\n",
        "\n",
        "\n",
        "# Instalar las integraciones de LangChain con diferentes proveedores de LLMs.\n",
        "%pip install langchain-openai -qU\n",
        "%pip install langchain-groq -qU\n",
        "%pip install langchain-google-genai -qU\n",
        "%pip install langchain-huggingface -qU\n",
        "%pip install langchain_mistralai -qU\n",
        "%pip install langchain-together -qU\n",
        "%pip install langchain-anthropic -qU\n",
        "\n",
        "# Importar las clases necesarias de LangChain para crear plantillas de prompt.\n",
        "# `ChatPromptTemplate` es la clase base para plantillas de chat.\n",
        "# `SystemMessagePromptTemplate` se usa para mensajes del sistema (instrucciones iniciales).\n",
        "# `HumanMessagePromptTemplate` se usa para mensajes del usuario.\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# Importar las clases para interactuar con los diferentes LLMs a través de LangChain.\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain_together import ChatTogether\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "\n",
        "# Importamos la libreria para formatear mejor la salida\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "0xW-bmL_pW00"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejemplo 1: Envolviendo funciones simples**\n",
        "---\n",
        "\n",
        "La forma principal de añadir una función a una cadena en Langchain (especialmente en LCEL) es utilizando RunnableLambda. RunnableLambda es un Runnable que envuelve una función Python, permitiéndole integrarse perfectamente en el flujo de la cadena.\n",
        "\n",
        "(Aunque es posible, la inserción directa de una función en una cadena funciona, esto se debe a que Langchain implícitamente envuelve esa función en un RunnableLambda \"por debajo del capó\" para que pueda encajar dentro del paradigma de la cadena LCEL. Es mejor ser consistente con los principios del framework y usar RunnableLambda)"
      ],
      "metadata": {
        "id": "-JBgg4CxpIkR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ihaYmy1rgga_",
        "outputId": "697f1ba8-bfeb-4339-d3e5-9cd311527610",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado de duplicar: 10\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# Función simple de Python\n",
        "def duplicar(x):\n",
        "    # Duplica el valor de entrada\n",
        "    return x * 2\n",
        "\n",
        "# Convertir a Runnable\n",
        "runnable_duplicar = RunnableLambda(duplicar)\n",
        "\n",
        "# Invocar el Runnable\n",
        "resultado = runnable_duplicar.invoke(5)\n",
        "print(f\"Resultado de duplicar: {resultado}\")  # Salida: 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2: Usando RunnableLambda en una cadena simple\n",
        "\n",
        "Múltiples `RunnableLambda` en secuencia. Este ejemplo muestra cómo encadenar múltiples `RunnableLambda`. La salida del primero (`runnable_mayusculas`) se convierte en la entrada del segundo\n",
        "(`runnable_exclamacion`)."
      ],
      "metadata": {
        "id": "jN_e2Pa1rQe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mayusculas(texto):\n",
        "    return texto.upper()\n",
        "\n",
        "def agregar_exclamacion(texto):\n",
        "    return texto + \"!\"\n",
        "\n",
        "runnable_mayusculas = RunnableLambda(mayusculas)\n",
        "runnable_exclamacion = RunnableLambda(agregar_exclamacion)\n",
        "\n",
        "cadena_transformacion = runnable_mayusculas | runnable_exclamacion\n",
        "\n",
        "resultado_transformacion = cadena_transformacion.invoke(\"Este es un texto cualquiera\")\n",
        "print(resultado_transformacion)"
      ],
      "metadata": {
        "id": "FgTwCRr9qod3",
        "outputId": "d341edd0-f2eb-4c5a-ebb9-ba66c7455a30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESTE ES UN TEXTO CUALQUIERA!\n"
          ]
        }
      ]
    }
  ]
}