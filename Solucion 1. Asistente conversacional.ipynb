{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfranbrv/curso-langchain/blob/main/Solucion%201.%20Asistente%20conversacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR5-dW-edsqa"
      },
      "source": [
        "Assistente conversacional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "dUEAeIGLdsqc"
      },
      "outputs": [],
      "source": [
        "# Importar la librería `userdata` de Google Colab.\n",
        "# Esta librería se utiliza para acceder a datos de usuario almacenados de forma segura en el entorno de Colab.\n",
        "from google.colab import userdata\n",
        "\n",
        "# Obtener las claves API de diferentes servicios desde el almacenamiento seguro de Colab.\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN=userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "# Instalar las librerías necesarias usando pip.\n",
        "# El flag `-qU` instala en modo silencioso (`-q`) y actualiza las librerías si ya están instaladas (`-U`).\n",
        "!pip install langchain -qU  # Instalar la librería principal de LangChain.\n",
        "\n",
        "# Instalar las integraciones de LangChain con diferentes proveedores de LLMs.\n",
        "!pip install langchain-openai -qU\n",
        "!pip install langchain-groq -qU\n",
        "!pip install langchain-google-genai -qU\n",
        "!pip install langchain-huggingface -qU\n",
        "\n",
        "# Importar las clases necesarias de LangChain para crear plantillas de prompt.\n",
        "# `ChatPromptTemplate` es la clase base para plantillas de chat.\n",
        "# `SystemMessagePromptTemplate` se usa para mensajes del sistema (instrucciones iniciales).\n",
        "# `HumanMessagePromptTemplate` se usa para mensajes del usuario.\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# Importar las clases para interactuar con los diferentes LLMs a través de LangChain.\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEndpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
        "                 api_key=OPENAI_API_KEY,\n",
        "                 temperature=0.7)"
      ],
      "metadata": {
        "id": "vtyLWCrmeaM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir las plantillas\n",
        "template_sistema = \"\"\"\\\n",
        "Eres un tutor amigable de {idioma}. Tu trabajo es:\n",
        "1. Mantener una conversación simple con el estudiante\n",
        "2. Corregir errores básicos de gramática y ortografía si los hay\n",
        "3. Ser paciente y motivador\n",
        "\"\"\"\n",
        "\n",
        "template_usuario = \"\"\"\\\n",
        "El estudiante dice: {mensaje_usuario}\n",
        "\n",
        "Por favor, responde de manera natural y si hay algún error gramatical,\n",
        "corrígelo sutilmente en tu respuesta.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WnhNMW6FepeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el ChatPromptTemplate\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(template_sistema),\n",
        "    HumanMessagePromptTemplate.from_template(template_usuario),\n",
        "])\n",
        "\n",
        "# Podria ser asi ???? explicar\n",
        "\n",
        "# Crear el ChatPromptTemplate\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", template_sistema),\n",
        "    (\"human\", template_usuario),\n",
        "])"
      ],
      "metadata": {
        "id": "wm3V7ogoewC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatear_en_idioma(mensaje_usuario, idioma=\"español\"):\n",
        "    \"\"\"\n",
        "    Función simple para procesar mensajes del usuario y obtener respuestas\n",
        "    1. Recibe el mensaje del usuario\n",
        "    2. Lo inyecta en el chatprompttemplate\n",
        "    3. Invoca el modelo con el\n",
        "    4. Devuelve la respuesta\n",
        "    \"\"\"\n",
        "    # Formatear el prompt con el mensaje del usuario y el idioma\n",
        "    prompt = chat_prompt.format(\n",
        "        mensaje_usuario=mensaje_usuario,\n",
        "        idioma=idioma\n",
        "    )\n",
        "\n",
        "    # Obtener la respuesta del modelo\n",
        "    respuesta = llm2.invoke(prompt)\n",
        "\n",
        "    return respuesta.content"
      ],
      "metadata": {
        "id": "hHmiu_rle0Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    print(\"¡Bienvenido al Chatbot de Aprendizaje de Idiomas!\")\n",
        "    print(\"Escribe 'salir' para terminar la conversación\")\n",
        "\n",
        "    while True:\n",
        "        # Obtener entrada del usuario\n",
        "        mensaje = input(\"\\nTú: \")\n",
        "\n",
        "        if mensaje.lower() == 'salir':\n",
        "            print(\"¡Hasta luego! Gracias por practicar.\")\n",
        "            break\n",
        "\n",
        "        # Obtener y mostrar la respuesta\n",
        "        respuesta = chatear_en_idioma(mensaje)\n",
        "        print(\"\\nTutor:\", respuesta)"
      ],
      "metadata": {
        "id": "3_jenBqIe5Gv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}