{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMONlFCeZJBM39aV9kch1zH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfranbrv/curso-langchain/blob/main/Agente%20con%20tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "\n",
        "# Importar la librería `userdata` de Google Colab.\n",
        "# Esta librería se utiliza para acceder a datos de usuario almacenados de forma segura en el entorno de Colab.\n",
        "from google.colab import userdata\n",
        "\n",
        "# Obtener las claves API de diferentes servicios desde el almacenamiento seguro de Colab.\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "# GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "# HUGGINGFACEHUB_API_TOKEN=userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "# El flag `-qU` instala en modo silencioso (`-q`) y actualiza las librerías si ya están instaladas (`-U`).\n",
        "%pip install langchain -qU  # Instalar la librería principal de LangChain.\n",
        "%pip install langgraph -qU\n",
        "\n",
        "# Instalar las integraciones de LangChain con diferentes proveedores de LLMs.\n",
        "%pip install langchain-openai -qU\n",
        "# %pip install langchain-groq -qU\n",
        "# %pip install langchain-google-genai -qU\n",
        "# %pip install langchain-huggingface -qU\n",
        "\n",
        "# Importar las clases necesarias de LangChain para crear plantillas de prompt.\n",
        "# `ChatPromptTemplate` es la clase base para plantillas de chat.\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "# Importamos las clases necesarias para trabajar con cadenas\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Importar las clases para interactuar con los diferentes LLMs a través de LangChain.\n",
        "from langchain_openai import ChatOpenAI\n",
        "# from langchain_groq import ChatGroq\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "# Importamos la libreria para formatear mejor la salida\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Para la anotacion de tipos\n",
        "from typing import Literal"
      ],
      "metadata": {
        "id": "OeL18zKyZBUP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ihaYmy1rgga_",
        "outputId": "3d65dea3-645b-42f4-c853-e6b79486b82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Cuantas veces se menciona fresa en la frase: Una fresa es de color fresa\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  frecuencia_palabra (call_2Jpjp10bUylAy7XkKHdyxlFI)\n",
            " Call ID: call_2Jpjp10bUylAy7XkKHdyxlFI\n",
            "  Args:\n",
            "    texto: Una fresa es de color fresa\n",
            "    palabra: fresa\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: frecuencia_palabra\n",
            "\n",
            "2\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "La palabra \"fresa\" se menciona 2 veces en la frase \"Una fresa es de color fresa\".\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import END, START, StateGraph, MessagesState\n",
        "from langgraph.prebuilt import tools_condition, ToolNode\n",
        "from langchain.agents import tool\n",
        "\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "# 1. DEFINIMOS EL ESQUEMA DEL ESTADO ===========================================\n",
        "# Siempre es algun tipo de diccionario\n",
        "\n",
        "class MyState(MessagesState):\n",
        "    # Hereda de MessagesState, que internamente guarda \"messages\"\n",
        "    # messages: list[AnyMessage]\n",
        "    # Podemos añadir campos extra si queremos\n",
        "    pass\n",
        "\n",
        "# 2. INSTANCIAMOS UN GRAFO =====================================================\n",
        "# Lo hacemos pasándole el tipo del estado al constructor\n",
        "\n",
        "grafo = StateGraph(MyState)\n",
        "\n",
        "# 3. CREAMOS LAS HERRAMIENTAS / FUNCIONES AUXILIARES ===========================\n",
        "# Funciones para nodos, arista condicionales y herramientas\n",
        "\n",
        "# Definir las herramientas\n",
        "@tool\n",
        "def contiene_numeros(texto: str) -> bool:\n",
        "    \"\"\"Verifica si el texto contiene números.\"\"\"\n",
        "    return any(caracter.isdigit() for caracter in texto)\n",
        "\n",
        "@tool\n",
        "def contar_caracteres(texto: str) -> int:\n",
        "    \"\"\"Cuenta el número total de caracteres en un texto, incluyendo espacios.\"\"\"\n",
        "    return len(texto)\n",
        "\n",
        "@tool\n",
        "def contar_caracteres_sin_espacios(texto: str) -> int:\n",
        "    \"\"\"Cuenta el número de caracteres en un texto, excluyendo espacios.\"\"\"\n",
        "    return len(texto.replace(\" \", \"\"))\n",
        "\n",
        "@tool\n",
        "def frecuencia_palabra(texto: str, palabra: str) -> int:\n",
        "    \"\"\"Cuenta cuántas veces aparece una palabra específica en un texto.\"\"\"\n",
        "    return texto.lower().split().count(palabra.lower())\n",
        "\n",
        "@tool\n",
        "def frecuencia_letra(texto: str, letra: str) -> int:\n",
        "    \"\"\"Cuenta cuántas veces aparece una letra específica en un texto.\"\"\"\n",
        "    return texto.lower().count(letra.lower())\n",
        "\n",
        "# Esta funcion es un nodo\n",
        "# Recibe el estado e invoca al LLM con los mensajes\n",
        "def agente(state: MyState) -> MyState:\n",
        "   return {\"messages\": [modelo_con_herramientas.invoke(state[\"messages\"])]}\n",
        "\n",
        "# 4. INSTANCIAMOS EL MODELO Y LE AÑADIMOS LAS HERRAMIENTAS =====================\n",
        "\n",
        "herramientas = [contiene_numeros,\n",
        "                contar_caracteres,\n",
        "                contar_caracteres_sin_espacios,\n",
        "                frecuencia_palabra,\n",
        "                frecuencia_letra]\n",
        "\n",
        "modelo = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, temperature=0)\n",
        "\n",
        "modelo_con_herramientas = modelo.bind_tools(herramientas)\n",
        "\n",
        "\n",
        "# 5. AÑADIMOS NODOS AL GRAFO ===================================================\n",
        "# Usamos la sintaxis graph.add_node(nombre, runnable)\n",
        "# nombre: el nombre del nodo\n",
        "# runnable: función o un ejecutable LCEL que se llamará al entrar al nodo\n",
        "# Esta función/LCEL debe aceptar un diccionario en el mismo formato que el ESTADO como entrada\n",
        "# Y devolver un diccionario tambien con el mismo formato que el estado, que sera el nuevo estado.\n",
        "\n",
        "# Añadimos el nodo y su arista en el grafo\n",
        "grafo.add_node(\"agente\", agente)\n",
        "grafo.add_node(\"tools\", ToolNode(herramientas))\n",
        "\n",
        "# Toolcondition redirecciona a un nodo por defcto que se tiene que llmar tools\n",
        "\n",
        "\n",
        "# 5. LÓGICA Y ARISTAS ==========================================================\n",
        "# El nodo inicial lo definimos haciendo uso de START\n",
        "\n",
        "grafo.add_edge(START, \"agente\")\n",
        "\n",
        "# Las aristas condicionales se definen usando el método\n",
        "# add_conditional_edges (nodo_origen, funcion)\n",
        "# La funcion de condicion se encarga de decidir (basandose en el estado) el nodo siguiente\n",
        "# DeBe devolver el nombre del nodo destino (str)\n",
        "\n",
        "grafo.add_conditional_edges(\"agente\",tools_condition)\n",
        "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
        "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
        "\n",
        "\n",
        "# Cualquier arista no condicional la creamos\n",
        "# grafo.add(nodo1, nodo2)\n",
        "\n",
        "grafo.add_edge(\"tools\", \"agente\")\n",
        "\n",
        "# 6. COMPILAMOS EL GRAFO =======================================================\n",
        "# Esto crea un LangChain Runnable\n",
        "# lo que implica que lo podemos usar como cualquier otro Runnable\n",
        "app = grafo.compile()\n",
        "\n",
        "# Show\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
        "\n",
        "# 7. EJECUTAMOS EL RUNNABLE ====================================================\n",
        "pregunta = \"Cuantas veces se menciona fresa en la frase: Una fresa es de color fresa\"\n",
        "respuesta = app.invoke({\"messages\": pregunta})\n",
        "for m in respuesta['messages']:\n",
        "    m.pretty_print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Refs\n",
        "# https://github.com/olonok69/LLM_Notebooks/blob/main/langchain/langgraph/LangGraph_agent_memory.ipynb\n",
        "# https://anderfernandez.com/blog/sistemas-de-agente-con-langgraph/\n",
        "# https://github.com/langchain-ai/langgraph/tree/main\n",
        "# https://blog.langchain.dev/langgraph/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de agente con LangGraph: múltiples nodos, herramientas y arista condicional\n",
        "\n",
        "from typing import Literal\n",
        "from langchain.agents import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import START, END, StateGraph, MessagesState\n",
        "\n",
        "# =============================================================================\n",
        "# 1. DEFINIMOS EL ESQUEMA DEL ESTADO\n",
        "# =============================================================================\n",
        "class MyMessagesState(MessagesState):\n",
        "    # Hereda de MessagesState, que internamente guarda \"messages\"\n",
        "    # Podemos añadir campos extra si queremos\n",
        "    detalle_extra: str = \"\"\n",
        "\n",
        "# Instanciamos el grafo\n",
        "grafo = StateGraph(MyMessagesState)\n",
        "\n",
        "# =============================================================================\n",
        "# 2. DEFINIMOS LAS HERRAMIENTAS (TOOLS)\n",
        "# =============================================================================\n",
        "@tool\n",
        "def traducir_ingles(texto: str) -> str:\n",
        "    \"\"\"Traducción *simple* (dummy) al inglés\"\"\"\n",
        "    return f\"(Traducción dummy al inglés): {texto}\"\n",
        "\n",
        "@tool\n",
        "def traducir_espanol(texto: str) -> str:\n",
        "    \"\"\"Traducción *simple* (dummy) al español\"\"\"\n",
        "    return f\"(Traducción dummy al español): {texto}\"\n",
        "\n",
        "@tool\n",
        "def revertir_texto(texto: str) -> str:\n",
        "    \"\"\"Revierte el texto (lo escribe al revés).\"\"\"\n",
        "    return texto[::-1]\n",
        "\n",
        "# =============================================================================\n",
        "# 3. DEFINIMOS LOS NODOS Y LA LÓGICA DEL GRAFO\n",
        "# =============================================================================\n",
        "\n",
        "def agente(state: MyMessagesState) -> MyMessagesState:\n",
        "    \"\"\"\n",
        "    Nodo inicial: aquí podrías hacer configuraciones, etc.\n",
        "    En este ejemplo, simplemente seguimos para que 'router' decida.\n",
        "    \"\"\"\n",
        "    # Podrías hacer algo con state.messages[-1], si quisieras.\n",
        "    return state\n",
        "\n",
        "def router(state: MyMessagesState) -> Literal[\"traducir_en\",\n",
        "                                              \"traducir_es\",\n",
        "                                              \"revertir\",\n",
        "                                              \"desconocido\"]:\n",
        "    \"\"\"\n",
        "    A partir del último mensaje del usuario, decide qué nodo sigue.\n",
        "    - Si detecta 'english' -> traducir_en\n",
        "    - Si detecta 'espanol' o 'spanish' -> traducir_es\n",
        "    - Si detecta 'revertir' -> revertir\n",
        "    - En caso contrario -> desconocido\n",
        "    \"\"\"\n",
        "    user_msg = state.messages[-1][1].lower()  # Contenido del último mensaje\n",
        "\n",
        "    if \"english\" in user_msg or \"inglés\" in user_msg:\n",
        "        return \"traducir_en\"\n",
        "    elif \"spanish\" in user_msg or \"español\" in user_msg:\n",
        "        return \"traducir_es\"\n",
        "    elif \"revertir\" in user_msg or \"reverse\" in user_msg:\n",
        "        return \"revertir\"\n",
        "    else:\n",
        "        return \"desconocido\"\n",
        "\n",
        "def traducir_en(state: MyMessagesState) -> MyMessagesState:\n",
        "    \"\"\"Nodo para traducir al inglés.\"\"\"\n",
        "    user_msg = state.messages[-1][1]\n",
        "    resultado = traducir_ingles.run(user_msg)\n",
        "    # Agregamos la respuesta de la IA\n",
        "    state.messages.append((\"ai\", resultado))\n",
        "    return state\n",
        "\n",
        "def traducir_es(state: MyMessagesState) -> MyMessagesState:\n",
        "    \"\"\"Nodo para traducir al español.\"\"\"\n",
        "    user_msg = state.messages[-1][1]\n",
        "    resultado = traducir_espanol.run(user_msg)\n",
        "    state.messages.append((\"ai\", resultado))\n",
        "    return state\n",
        "\n",
        "def revertir(state: MyMessagesState) -> MyMessagesState:\n",
        "    \"\"\"Nodo para revertir el texto.\"\"\"\n",
        "    user_msg = state.messages[-1][1]\n",
        "    resultado = revertir_texto.run(user_msg)\n",
        "    state.messages.append((\"ai\", f\"Texto revertido: {resultado}\"))\n",
        "    return state\n",
        "\n",
        "def desconocido(state: MyMessagesState) -> MyMessagesState:\n",
        "    \"\"\"Nodo de fallback si no se reconoce la petición.\"\"\"\n",
        "    state.messages.append((\"ai\", \"Lo siento, no entendí tu petición.\"))\n",
        "    return state\n",
        "\n",
        "# =============================================================================\n",
        "# 4. CONFIGURAMOS EL MODELO (LLM) CON LAS HERRAMIENTAS\n",
        "# =============================================================================\n",
        "# En tu caso, \"gpt-4o-mini\" existe y es válido.\n",
        "# Aquí lo dejamos, o puedes cambiarlo por un modelo real como \"gpt-3.5-turbo\".\n",
        "OPENAI_API_KEY = \"TU_API_KEY\"  # Asegúrate de inyectarla\n",
        "modelo = ChatOpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY, temperature=0)\n",
        "\n",
        "modelo_con_herramientas = modelo.bind_tools([\n",
        "    traducir_ingles,\n",
        "    traducir_espanol,\n",
        "    revertir_texto\n",
        "])\n",
        "\n",
        "# =============================================================================\n",
        "# 5. AÑADIMOS LOS NODOS Y LAS ARISTAS AL GRAFO\n",
        "# =============================================================================\n",
        "grafo.add_node(\"agente\", agente)\n",
        "grafo.add_node(\"traducir_en\", traducir_en)\n",
        "grafo.add_node(\"traducir_es\", traducir_es)\n",
        "grafo.add_node(\"revertir\", revertir)\n",
        "grafo.add_node(\"desconocido\", desconocido)\n",
        "\n",
        "# Aristas:\n",
        "# - START -> agente\n",
        "grafo.add_edge(START, \"agente\")\n",
        "\n",
        "# - agente -> router (arista condicional)\n",
        "grafo.add_conditional_edges(\"agente\", router)\n",
        "\n",
        "# No hace falta crear edges a la inversa, porque queremos que el flujo\n",
        "# termine en alguno de los nodos finales, pero si lo deseas, podrías\n",
        "# conectar con \"agente\" de nuevo. Aquí lo dejamos lineal.\n",
        "\n",
        "# =============================================================================\n",
        "# 6. COMPILAMOS EL GRAFO EN UN RUNNABLE\n",
        "# =============================================================================\n",
        "app = grafo.compile()\n",
        "\n",
        "# =============================================================================\n",
        "# 7. EJECUTAMOS UN EJEMPLO\n",
        "# =============================================================================\n",
        "# Mensaje de ejemplo para \"revertir\" texto\n",
        "pregunta = MyMessagesState(\n",
        "    messages=[\n",
        "        (\"system\", \"Eres un agente que puede traducir al inglés, español o revertir texto.\"),\n",
        "        (\"human\", \"Por favor, revertir este texto: Hola Mundo!\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "estado_respuesta = app.invoke(pregunta)\n",
        "estado_respuesta.pretty_print()\n",
        "\n",
        "# También podemos invocar otra pregunta:\n",
        "pregunta_2 = MyMessagesState(\n",
        "    messages=[\n",
        "        (\"system\", \"Eres un agente que puede traducir al inglés, español o revertir texto.\"),\n",
        "        (\"human\", \"¿Puedes traducir esto a English? 'Hola, me encanta programar.'\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "estado_respuesta_2 = app.invoke(pregunta_2)\n",
        "estado_respuesta_2.pretty_print()\n"
      ],
      "metadata": {
        "id": "Q_DMuKDonuB8",
        "outputId": "f308ac03-b163-48ba-e282-afcb821af169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'messages'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-20c00a667a8f>\u001b[0m in \u001b[0;36m<cell line: 148>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m \u001b[0mestado_respuesta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpregunta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0mestado_respuesta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   1941\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1661\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/graph/graph.py\u001b[0m in \u001b[0;36m_route\u001b[0;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-20c00a667a8f>\u001b[0m in \u001b[0;36mrouter\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0mEn\u001b[0m \u001b[0mcaso\u001b[0m \u001b[0mcontrario\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdesconocido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0muser_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Contenido del último mensaje\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"english\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_msg\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"inglés\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'messages'"
          ]
        }
      ]
    }
  ]
}