{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOrYsPAnVHB+lhm4UPbGjF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfranbrv/curso-langchain/blob/main/PydanticOutputParser_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ihaYmy1rgga_"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "\n",
        "# Importar la librería `userdata` de Google Colab.\n",
        "# Esta librería se utiliza para acceder a datos de usuario almacenados de forma segura en el entorno de Colab.\n",
        "from google.colab import userdata\n",
        "\n",
        "# Obtener las claves API de diferentes servicios desde el almacenamiento seguro de Colab.\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN=userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "MISTRAL_API_KEY=userdata.get('MISTRAL_API_KEY')\n",
        "TOGETHER_API_KEY=userdata.get('TOGETHER_API_KEY')\n",
        "ANTHROPIC_API_KEY=userdata.get('ANTHROPIC_API_KEY')\n",
        "DEEPSEEK_API_KEY=userdata.get('DEEPSEEK_API_KEY')\n",
        "\n",
        "\n",
        "# Instalar las librerías necesarias usando pip.\n",
        "# El flag `-qU` instala en modo silencioso (`-q`) y actualiza las librerías si ya están instaladas (`-U`).\n",
        "%pip install langchain -qU  # Instalar la librería principal de LangChain.\n",
        "\n",
        "\n",
        "# Instalar las integraciones de LangChain con diferentes proveedores de LLMs.\n",
        "%pip install langchain-openai -qU\n",
        "%pip install langchain-groq -qU\n",
        "%pip install langchain-google-genai -qU\n",
        "%pip install langchain-huggingface -qU\n",
        "%pip install langchain_mistralai -qU\n",
        "%pip install langchain-together -qU\n",
        "%pip install langchain-anthropic -qU\n",
        "\n",
        "# Importar las clases necesarias de LangChain para crear plantillas de prompt.\n",
        "# `ChatPromptTemplate` es la clase base para plantillas de chat.\n",
        "# `SystemMessagePromptTemplate` se usa para mensajes del sistema (instrucciones iniciales).\n",
        "# `HumanMessagePromptTemplate` se usa para mensajes del usuario.\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# Importar las clases para interactuar con los diferentes LLMs a través de LangChain.\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain_together import ChatTogether\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# Modelo Pydantic para respuesta simple\n",
        "class TranslationOutput(BaseModel):\n",
        "    translation: str = Field(description=\"The professional translated text\")\n",
        "\n",
        "# Modelo Pydantic para respuesta de un modelo corrector\n",
        "class RespuestaAgente (BaseModel):\n",
        "    translation: str = Field(description=\"Texto con la traduccion generada por el agente.\")\n",
        "    suggestions: List[str] = Field(description=\"Lista de suggestions encontradas en el texto.\")\n",
        "\n",
        "parser_translation = PydanticOutputParser(pydantic_object=TranslationOutput)\n",
        "parser_agent = PydanticOutputParser(pydantic_object=RespuestaAgente)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "LNbNy39c1e8y"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"You are a senior legal translator specializing in Intellectual Property documents. \"\n",
        "        \"Translate the text from {source_language} to {target_language} with:\\n\"\n",
        "        \"- Perfect accuracy\\n\"\n",
        "        \"- Legal terminology consistency\\n\"\n",
        "        \"- Publication-ready quality\\n\\n\"\n",
        "        \"**Strict instructions:**\\n\"\n",
        "        \"1. Output MUST be valid JSON with double quotes\\n\"\n",
        "        \"2. Follow EXACTLY this structure:\\n\"\n",
        "        \"3. Do not include any additional text or explanations.\"\n",
        "    )),\n",
        "    (\"human\", (\n",
        "        \"Translate this legal text with absolute precision:\\n\"\n",
        "        \"{original_text}\\n\\n\"\n",
        "        \"Output ONLY the required JSON:\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Configurar las variables de entrada\n",
        "translator_prompt_template = translator_prompt_template.partial(\n",
        "    format_instructions=parser_translation.get_format_instructions()\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "accuracy_reviewer_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", (\n",
        "        \"You are an Accuracy Reviewer specializing in {source_language} to {target_language} translations.\\n\"\n",
        "        \"**Strict instructions:**\\n\"\n",
        "        \"1. Follow EXACTLY this structure:\\n\"\n",
        "        \"2. Return a JSON object with EXACTLY these fields:\\n\"\n",
        "        \"   - 'translation': corrected translation text\\n\"\n",
        "        \"   - 'suggestions': list of suggestions using format '- ERROR: [issue] -> SUGGESTION: [fix]'\\n\\n\"\n",
        "        \"3. Follow these rules:\\n\"\n",
        "        \"- Correct only accuracy errors (mistranslations, omissions, untranslated text)\\n\"\n",
        "        \"- Maintain original style and format\\n\"\n",
        "        \"- If no changes, return original text and empty list\\n\"\n",
        "        \"- Use exactly the specified JSON structure\"\n",
        "    )),\n",
        "    (\"human\", (\n",
        "        \"Original Text ({source_language}):\\n\"\n",
        "        \"{original_text}\\n\\n\"\n",
        "        \"Current Translation ({target_language}):\\n\"\n",
        "        \"{translation}\\n\\n\"\n",
        "        \"Provide corrections in the required JSON format.\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Configuración adicional para el parser\n",
        "accuracy_reviewer_prompt_template = accuracy_reviewer_prompt_template.partial(\n",
        "    format_instructions=parser_agent.get_format_instructions()\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SBuTaU_F2Uxg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = ChatOpenAI(model=\"gpt-4o-mini\",api_key=OPENAI_API_KEY, temperature=1)\n",
        "llm =  ChatGroq(model=\"deepseek-r1-distill-llama-70b\", api_key=GROQ_API_KEY, temperature=1.3)"
      ],
      "metadata": {
        "id": "AnrE-u0P2yD2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo recibira un texto original, una traduccion y debe realizar una correccion de la traduccion.\n",
        "Como resultado debe devolver una nueva traduccion y una lista con los problema encontrados en cierto formato"
      ],
      "metadata": {
        "id": "RXJ40o0J3lrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_text='And according to Bertrand Russell, \"the man who has no tincture of philosophy goes through life imprisoned in the prejudices derived from common sense, from the habitual beliefs of his age or his nation, and from convictions which have grown up in his mind without the cooperation or consent of his deliberate reason.'"
      ],
      "metadata": {
        "id": "DtwpYJ512Rru"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator_prompt = translator_prompt_template.format(source_language=\"English\",\n",
        "                                         target_language=\"Spanish\",\n",
        "                                         original_text=original_text,\n",
        "                                         )"
      ],
      "metadata": {
        "id": "lzI5P3o0rrgc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "translator_chain = translator_prompt_template | llm | parser_translation\n",
        "accuracy_reviewer_chain = accuracy_reviewer_prompt_template | llm | parser_agent\n",
        "\n",
        "\n",
        "full_chain = RunnablePassthrough.assign(translation=translator_chain) | accuracy_reviewer_chain\n",
        "\n",
        "# Esto no puede ser\n",
        "refull_chain =  translator_prompt_template | llm | parser_translation | accuracy_reviewer_prompt_template | llm | parser_agent"
      ],
      "metadata": {
        "id": "Dr7iYNhK1HOz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultado_final = full_chain.invoke({\n",
        "    \"source_language\": \"English\",\n",
        "    \"target_language\": \"Spanish\",\n",
        "    \"original_text\": original_text\n",
        "})"
      ],
      "metadata": {
        "id": "rEzcmdGHsB5F"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como hacerlo sin encadenar todo en una sola cadena"
      ],
      "metadata": {
        "id": "rdwV0vFvQuhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = translator_chain.invoke({\n",
        "        \"source_language\": \"English\",\n",
        "        \"target_language\": \"Spanish\",\n",
        "        \"original_text\": original_text\n",
        "    })\n",
        "\n",
        "print(type(result))\n",
        "print(result.translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28bc1DQlQz5z",
        "outputId": "7db403e1-ebdd-4dab-a6b8-0146f29c5e71"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.TranslationOutput'>\n",
            "Y según Bertrand Russell, \"el hombre que no tiene ninguna tintura de filosofía atraviesa la vida encerrado en los prejuicios derivados del sentido común, en las creencias habituales de su época o su nación, y en las convicciones que han crecido en su mente sin la cooperación o consentimiento de su razón deliberada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = accuracy_reviewer_chain.invoke({\n",
        "        \"source_language\": \"English\",\n",
        "        \"target_language\": \"Spanish\",\n",
        "        \"original_text\": original_text,\n",
        "        \"translation\": result.translation\n",
        "    })\n",
        "\n",
        "pprint(type(result2))\n",
        "pprint(result2.translation)\n",
        "for suggestion in result2.suggestions:\n",
        "    print(suggestion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPxmEcoAil7Y",
        "outputId": "7d7351b5-1f3b-4063-cccd-1d5284fce9ac"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.RespuestaAgente'>\n",
            "('Y según Bertrand Russell, \"el hombre que no tiene tintura de filosofía '\n",
            " 'atraviesa la vida encerrado en los prejuicios derivados del sentido común, '\n",
            " 'de las creencias habituales de su época o su nación, y en las convicciones '\n",
            " 'que se han desarrollado en su mente sin la cooperación o consentimiento de '\n",
            " 'su razón deliberada.')\n",
            "- ERROR: The phrase 'no tiene ninguna tintura' is redundant. -> SUGGESTION: Simplify to 'no tiene tintura'\n",
            "- ERROR: 'han crecido' is not entirely accurate for 'have grown up in his mind' -> SUGGESTION: Change to 'se han desarrollado'\n",
            "- ERROR: The pronoun 'su' before 'razón deliberada' is redundant -> SUGGESTION: Remove 'su'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "crear graficos que explican el sistema encadenado, el no encadenado\n",
        "(lo que entra y lo que sale)\n",
        "\n",
        "y tambien la arquitectura lineal\n",
        "y la que podria ser RunnableParallel\n"
      ],
      "metadata": {
        "id": "0mi-frhyjjKW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MPKCHlvojpWz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}