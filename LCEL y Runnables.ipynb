{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPy1Q7VLTp4/4NGD3GGj7p7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanfranbrv/curso-langchain/blob/main/LCEL%20y%20Runnables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. LangChain Expression Language (LCEL)**\n",
        "---\n",
        "\n",
        "LCEL se introdujo en Langchain **a mediados de 2023**, específicamente con la **versión 0.0.142**, lanzada el **19 de julio de 2023**\n",
        "\n",
        "La introducción de **LCEL** en Langchain fue una respuesta a la necesidad de una forma más potente, flexible y fácil de usar para construir aplicaciones de lenguaje complejas. Proporcionó una sintaxis declarativa, mejoró la legibilidad, facilitó la depuración y habilitó funcionalidades avanzadas como el streaming y la ejecución asíncrona, consolidándose como una pieza fundamental del ecosistema de Langchain.\n",
        "\n",
        "En LCEL no existen tipos de cadenas predefinidos como \"secuenciales\", \"condicionales\" o \"paralelas\". Sin embargo, puedes implementar estos patrones de flujo de trabajo utilizando la sintaxis de LCEL junto con funciones adicionales.  \n",
        "\n",
        "**LCEL se basa en la Composición, no en Tipos Predefinidos:**\n",
        "\n",
        "-   **Operador Pipe (|):** La piedra angular de LCEL es el operador pipe. Este operador te permite encadenar componentes de forma secuencial, enviando la salida de un componente como entrada al siguiente. Esto es inherentemente secuencial, pero no se define como un tipo de cadena \"secuencial\".\n",
        "    \n",
        "-   **Primitivas Runnable:** LCEL se basa en la interfaz Runnable. Cualquier objeto que implemente esta interfaz puede ser parte de una cadena LCEL. Esto incluye modelos de lenguaje, prompts, parsers, retrievers, etc.\n",
        "    \n",
        "-   **Flexibilidad Total:** La clave es que puedes combinar estas primitivas Runnable de cualquier manera que tenga sentido para tu aplicación. No estás limitado a estructuras predefinidas.\n",
        "\n",
        "**Ventajas de este enfoque:**\n",
        "\n",
        "-   **Mayor Flexibilidad:** No estás limitado por las estructuras predefinidas. Puedes crear flujos de trabajo exactamente como los necesitas.\n",
        "    \n",
        "-   **Reutilización de Componentes:** Los componentes individuales pueden ser reutilizados en diferentes cadenas con diferentes flujos de trabajo.\n",
        "    \n",
        "-   **Claridad y Composición:** El uso del operador pipe hace que la lógica de la cadena sea más clara y fácil de entender.\n",
        "    \n",
        "-   **Optimización:** La forma en que construyes la cadena influye en cómo se puede optimizar su ejecución (por ejemplo, para paralelismo).\n",
        "    \n",
        "\n",
        "**En resumen, LCEL te proporciona las herramientas y la sintaxis para orquestar tus flujos de trabajo de manera flexible y poderosa. En lugar de imponer tipos de cadenas predefinidos, te da la libertad de construir las cadenas que mejor se adapten a tus necesidades, implementando patrones secuenciales, condicionales o paralelos según sea necesario.**\n",
        "\n",
        "Y todo esta abstración se basa en los **Runnables**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p9n7xOvQEQ6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Runnables**\n",
        "---\n",
        "\n",
        "Un *“Runnable”* en LangChain es una abstracción (una interfaz en código) que define un contrato para ejecutar una operación. Concretamente, un `Runnable` expone un método `invoke(input)`, el cual recibe un dato de entrada y produce un resultado de salida. Así, cualquier clase u objeto que cumpla con esta interfaz puede encadenarse o combinarse con otros `Runnables` para construir flujos de trabajo complejos (por ejemplo, secuencias o ejecuciones en paralelo).   \n",
        "\n",
        "Cada \"*Runnable*\" implementa métodos como invoke, batch, stream, y transform, lo que lo hace compatible con diferentes modos de ejecución (sincrónica, asincrónica, en lote, etc.).  \n",
        "Esto permite orquestar y reutilizar fácilmente distintas operaciones dentro de LangChain.\n",
        "\n",
        "Un poco menos técnico...\n",
        "\n",
        "Un *“Runnable”* es como una función que sabe hacer algo muy concreto: recibe cierta información y devuelve un resultado. Lo importante es que, en LangChain, todos los *“Runnables”* siguen la misma “forma de trabajar”. Gracias a esto, podemos ir uniendo varios “Runnables” uno tras otro o en paralelo para crear procesos más grandes sin tener que hacer ajustes complicados. En otras palabras, si cada bloque (*Runnable*) sabe cómo recibir datos y devolverlos transformados, podemos combinar esos bloques como si fueran piezas de LEGO para armar flujos de trabajo completos.\n",
        "\n",
        "## Conceptos clave de runnables\n",
        "-   **Modularidad**\n",
        "    \n",
        "    -   Cada Runnable representa una única tarea u operación (p.ej., ejecutar un modelo, procesar datos, encadenar operaciones).\n",
        "    -   Su diseño en “bloques” facilita la independencia y el intercambio de componentes.\n",
        "-   **Componibilidad**\n",
        "    \n",
        "    -   Varios Runnables pueden vincularse para formar canalizaciones o flujos de trabajo complejos.\n",
        "    -   Esto permite crear soluciones más grandes a partir de piezas pequeñas, flexibles y reutilizables.\n",
        "-   **Reutilizabilidad**\n",
        "    \n",
        "    -   Una vez definido, un Runnable se puede integrar en distintos proyectos sin modificaciones.\n",
        "    -   Es ideal para tareas estándar que se repiten (p.ej., preprocesamiento de datos).\n",
        "-   **Ejecución asincrónica**\n",
        "    \n",
        "    -   Los Runnables pueden ejecutarse de forma asíncrona, optimizando recursos y tiempo, especialmente cuando hay llamadas a servicios externos o E/S de por medio.\n",
        "\n",
        "-   **Ejecución paralela**\n",
        "    \n",
        "    -   Es posible configurar Runnables para que se ejecuten en paralelo, lo que mejora el rendimiento en tareas por lotes o cuando se manejan grandes volúmenes de datos.\n",
        "-   **Manejo de errores**\n",
        "    \n",
        "    -   Suelen incluir mecanismos para capturar y gestionar excepciones, reforzando la solidez del flujo de trabajo.\n",
        "-   **Registro y depuración**\n",
        "    \n",
        "    -   Admiten el registro de metadatos y eventos, lo que facilita rastrear y depurar la ejecución de principio a fin.\n"
      ],
      "metadata": {
        "id": "TXNoJRERJ5l2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Chains (Cadenas)**\n",
        "---\n",
        "\n",
        "En Langchain, una Cadena (Chain) representa una secuencia orquestada de llamadas a uno o más Runnables para realizar una tarea específica. Piensa en ella como una tubería o un flujo de trabajo donde la salida de un Runnable se convierte en la entrada del siguiente.  \n",
        "\n",
        "En esencia, una Cadena combina la funcionalidad de múltiples Runnables para llevar a cabo procesos más complejos que los que un solo Runnable podría manejar individualmente. Las Cadenas son el mecanismo principal en Langchain para construir aplicaciones de lenguaje natural con lógica y pasos definidos."
      ],
      "metadata": {
        "id": "dVHiL2gmcWJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Primitivas Runnables\n",
        "\n",
        "** Dado que es un área de la librería en evolución, es posible que se agreguen o refinen más “runnables” en versiones futuras.\n",
        "\n"
      ],
      "metadata": {
        "id": "fG7vAQWRR8pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Preparando el entorno del cuaderno\n",
        "Configuramos el entorno de trabajo para utilizar LangChain con distintos modelos de lenguaje (LLMs).\n",
        "\n",
        "- Obtenemos las claves API para acceder a los servicios de OpenAI, Groq, Google y Hugging Face.\n",
        "\n",
        "- Instalamos la librería LangChain y las integraciones necesarias para cada uno de estos proveedores.\n",
        "\n",
        "- Importamos las clases específicas de LangChain que permiten crear plantillas de prompts e interactuar con los diferentes modelos de lenguaje, dejándolo todo listo para empezar a desarrollar aplicaciones basadas en LLMs. (Este codigo se explico con detalle en el primer cuaderno)\n",
        "\n",
        "Comenta (#) las librerias y modelos que no desees usar."
      ],
      "metadata": {
        "id": "Uv1UDKaYSP4n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihaYmy1rgga_"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "\n",
        "# Importar la librería `userdata` de Google Colab.\n",
        "# Esta librería se utiliza para acceder a datos de usuario almacenados de forma segura en el entorno de Colab.\n",
        "from google.colab import userdata\n",
        "\n",
        "# Obtener las claves API de diferentes servicios desde el almacenamiento seguro de Colab.\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN=userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "# Instalar las librerías necesarias usando pip.\n",
        "# El flag `-qU` instala en modo silencioso (`-q`) y actualiza las librerías si ya están instaladas (`-U`).\n",
        "%pip install langchain -qU  # Instalar la librería principal de LangChain.\n",
        "%pip install langchain-community  -qU # Instalar el paquete langchain-community, necesario para los Loaders\n",
        "\n",
        "# Instalar las integraciones de LangChain con diferentes proveedores de LLMs.\n",
        "%pip install langchain-openai -qU\n",
        "%pip install langchain-groq -qU\n",
        "%pip install langchain-google-genai -qU\n",
        "%pip install langchain-huggingface -qU\n",
        "\n",
        "# Importar las clases necesarias de LangChain para crear plantillas de prompt.\n",
        "# `ChatPromptTemplate` es la clase base para plantillas de chat.\n",
        "# `SystemMessagePromptTemplate` se usa para mensajes del sistema (instrucciones iniciales).\n",
        "# `HumanMessagePromptTemplate` se usa para mensajes del usuario.\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "# Importar las clases para interactuar con los diferentes LLMs a través de LangChain.\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "# Importamos la libreria para formatear mejor la salida\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referencias:\n",
        "\n",
        "1. https://python.langchain.com/docs/concepts/runnables/\n",
        "\n",
        "2. Info oficial: https://python.langchain.com/api_reference/core/runnables.html\n",
        "3. https://python.langchain.com/docs/how_to/lcel_cheatsheet/\n",
        "\n",
        "4. https://dzone.com/articles/guide-to-langchain-runnable-architecture\n",
        "\n",
        "5. https://medium.com/@danushidk507/runnables-in-langchain-e6bfb7b9c0ca\n",
        "\n",
        "6. https://www.youtube.com/watch?v=8aUYzb1aYDU\n",
        "\n",
        "7. https://medium.com/@james.li/mental-model-to-building-chains-with-langchain-expression-language-lcel-with-branching-and-36f185134eac\n",
        "\n",
        "8. https://medium.com/@ulrichw/list/langchain-lcel-85af4f4ff883\n",
        "\n",
        "9. https://medium.com/@anuragmishra_27746/practical-hands-on-with-langchain-expression-language-lcel-for-building-langchain-agent-chain-2a9364dc4ca3\n",
        "\n",
        "10. https://www.pinecone.io/learn/series/langchain/langchain-expression-language/\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oJd-xV-oMuhQ"
      }
    }
  ]
}